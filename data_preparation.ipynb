{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74d437cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from astropy.time import Time\n",
    "from scipy.interpolate import interp1d\n",
    "import math\n",
    "import copy\n",
    "import glob\n",
    "import subprocess\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "588346d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#some useful functions\n",
    "\n",
    "# Read all files for a given instrument, resample and concatenate\n",
    "def read_single_meteo_file(filename,keep=['Date', 'pressure', 'Temperature', 'Humidity', 'windSpeed', 'windDir'],set_index=True):\n",
    "    df = pd.read_csv(filename, header=1, parse_dates={'Date':['YYYY/MM/JJ',' hh:mn:sec(HL)']})\n",
    "    # Remove spaces in column names\n",
    "    df.rename(str.strip,axis='columns',inplace=True)\n",
    "    # Rename some columns\n",
    "    df.rename(columns={\"outTemp\": \"Temperature\", \"outHumidity\": \"Humidity\"},inplace=True)\n",
    "    if (keep != 'all'):\n",
    "        columns=keep\n",
    "        index_to_remove = df.columns.drop(keep)\n",
    "        df = df.drop(columns=index_to_remove)\n",
    "    if (set_index):\n",
    "        # Use Date as index\n",
    "        df.set_index('Date',inplace=True)\n",
    "    return (df)\n",
    "\n",
    "def read_single_pml_file(filename,keep=['Date', 'Seeing', 'Cn2_ground', 'Cn2_150', 'Cn2_250'],set_index=True):\n",
    "    df = pd.read_csv(filename,header=22,parse_dates={'Datetmp':['Date','Time_UT']})\n",
    "    df.rename(columns={\"Datetmp\": \"Date\", \"Tau0(ms)\": \"Tau0\", \"Seeing[arcsec]\": \"Seeing\", \"Isop[arcsec]\": \"Isop\"},inplace=True)\n",
    "    if (keep != 'all'):\n",
    "        index_to_remove = df.columns.drop(keep)\n",
    "        df = df.drop(columns=index_to_remove)\n",
    "    if (set_index):\n",
    "        df.set_index('Date',inplace=True)\n",
    "    return(df)\n",
    "\n",
    "def read_single_gdimm_file(filename,keep=['Seeing', 'Date', 'Isop', 'Tau0'],set_index=True):\n",
    "    df = pd.read_csv(filename,header=20,parse_dates={'Datetmp':['Date','Time_UT']})\n",
    "    df.rename(columns={\"Datetmp\": \"Date\", \"Tau0(ms)\": \"Tau0\"},inplace=True)\n",
    "    df.insert(16, 'Seeing', 0.5*(df['epsT']+df['epsL']))\n",
    "\n",
    "    if (keep != 'all'):\n",
    "        index_to_remove = df.columns.drop(keep)\n",
    "        df  = df.drop(columns=index_to_remove)\n",
    "    if (set_index):\n",
    "        df.set_index('Date',inplace=True)\n",
    "    return (df)\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "# Routine to prepare training samples from single contiguous dataframe\n",
    "def split_series(series, n_past, n_future, out_column_index=5):\n",
    "    #\n",
    "    # n_past ==> no of past observations\n",
    "    #\n",
    "    # n_future ==> no of future observations \n",
    "    #\n",
    "    out_column_index\n",
    "    X, y = list(), list()\n",
    "    for window_start in range(len(series)):\n",
    "        past_end = window_start + n_past\n",
    "        future_end = past_end + n_future\n",
    "        if future_end > len(series):\n",
    "            break\n",
    "        # slicing the past and future parts of the window\n",
    "        past, future = series[window_start:past_end, :], series[past_end:future_end, [out_column_index]]\n",
    "        X.append(past)\n",
    "        y.append(future)\n",
    "    return np.array(X), np.array(y)  \n",
    "\n",
    "\n",
    "# Routine to fill missing values with random values from data distribution\n",
    "def fill_missing_values(dataframe,random=False):\n",
    "\n",
    "    if (random):\n",
    "        columns = dataframe.columns\n",
    "        for col in columns:\n",
    "            mean = dataframe[col].mean()\n",
    "            std  = dataframe[col].std() \n",
    "            mask_nans = dataframe[col].isnull().values\n",
    "            randoms = np.random.standard_normal(mask_nans.sum())*std + mean\n",
    "            dataframe.loc[mask_nans,col]=randoms\n",
    "    else:\n",
    "        dataframe.interpolate(method='spline',order=3,inplace=True)\n",
    "    return(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e976bc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_data_preparation(data_dir = '/Users/cgiordano/Documents/Travail/WRF/Calern_ML/Data', \n",
    "                     meteo_dir='CATS',meteo_tag='meteo_cats_*.csv',\n",
    "                     gdimm_dir='GDIMM_tmp',gdimm_tag='new_r0Alt_2*.csv',\n",
    "                     pml_dir='PBL_tmp',pml_tag='new_Cn2_2*.csv',\n",
    "                     sampling_rate_min=5,interpolate=True,day_only=True):\n",
    "\n",
    "    sampling_rate_str = '%dmin'%sampling_rate_min\n",
    "    \n",
    "\n",
    "    GDIMM_files = sorted(glob.glob(data_dir+'/'+gdimm_dir+'/'+gdimm_tag))\n",
    "    nGDIMM = len(GDIMM_files)\n",
    "    PML_files = sorted(glob.glob(data_dir+'/'+pml_dir+'/'+pml_tag))\n",
    "    nPML = len(PML_files)\n",
    "    METEO_files = np.array(glob.glob(data_dir+'/'+meteo_dir+'/'+meteo_tag))\n",
    "    filetest = np.array(['-'.join(item.split('_')[-1].split('.')[0].split('-')[::-1]) for item in METEO_files])\n",
    "    idx = np.argsort(filetest)\n",
    "    METEO_files = [item for item in METEO_files[idx]]\n",
    "    nMETEO = len(METEO_files)\n",
    "    # return (gdimm_files,pml_files,meteo_files)\n",
    "    \n",
    "\n",
    "    framelist=[]\n",
    "    for file in GDIMM_files:\n",
    "        #print(\"Processing file %s\"%file)\n",
    "        df = read_single_gdimm_file(file)\n",
    "        if (len(df)==0):\n",
    "            continue\n",
    "        df = df.resample(sampling_rate_str).bfill()\n",
    "        if (interpolate):\n",
    "            df.interpolate('spline',order=1,inplace=True)\n",
    "        framelist.append (df)\n",
    "    gdimm_data = pd.concat(framelist)\n",
    "    print('gdimm_data',gdimm_data)\n",
    " \n",
    "\n",
    "\n",
    "    framelist=[]\n",
    "    for file in PML_files:\n",
    "        #print(\"Processing file %s\"%file)\n",
    "        df = read_single_pml_file(file)\n",
    "        if (len(df)==0):\n",
    "            continue\n",
    "        df = df.resample(sampling_rate_str).bfill()\n",
    "        if (interpolate):\n",
    "            df.interpolate('spline',order=1,inplace=True)\n",
    "        framelist.append(df)\n",
    "    pml_data = pd.concat(framelist)\n",
    "    print('pml_data',pml_data)\n",
    "   \n",
    "\n",
    "    framelist = []\n",
    "    for file in METEO_files:\n",
    "        #print(\"Processing file %s\"%file)\n",
    "        df = read_single_meteo_file(file)\n",
    "        if (len(df)==0):                  \n",
    "            continue\n",
    "        df = df.resample(sampling_rate_str).bfill()\n",
    "        if (interpolate):\n",
    "            df.interpolate('spline',order=1,inplace=True)\n",
    "        framelist.append(df)\n",
    "    meteo_data = pd.concat(framelist)\n",
    "    print('meteo_data',meteo_data)\n",
    "    \n",
    "\n",
    "    \n",
    "    # Now do some merging of data. First outer join of pml and gdimm, and take (nan)mean of seing values as final seeing value\n",
    "    # This will allow to have seeing measurements during days and nights. It's ok because overlapping measurements are broadly compatible\n",
    "\n",
    "    if not day_only:\n",
    "\n",
    "        gdimm_pml = pd.merge(pml_data,gdimm_data,left_index=True,right_index=True,how='outer',suffixes=['_pml','_gdimm'])\n",
    "        seeing_gdimm = gdimm_pml['Seeing_gdimm'].values\n",
    "        seeing_pml   = gdimm_pml['Seeing_pml'].values\n",
    "        seeing = np.nanmean(np.vstack((seeing_gdimm,seeing_pml)),axis=0)\n",
    "        gdimm_pml['Seeing']=seeing\n",
    "        # Get rid of per instrument seeing measurements, just keep mean seeing value\n",
    "        gdimm_pml.drop(columns=['Seeing_gdimm','Seeing_pml'])\n",
    "        to_merge = gdimm_pml\n",
    "    else:\n",
    "        to_merge = pml_data # Do not include night only gdimm data\n",
    "    \n",
    "    print('to_merge',to_merge)\n",
    "\n",
    "    # Now (inner) merge with meteo data\n",
    "    final = pd.merge(meteo_data,to_merge,left_index=True,right_index=True)\n",
    "    \n",
    "    print('final',final)\n",
    "    \n",
    "    # OK, some final filtering\n",
    "    final[final.values<0]=np.nan\n",
    "    final.Seeing[final.Seeing.values>5]=np.nan\n",
    "    # Now check if we have the day_only filter\n",
    "    # Drop some columns\n",
    "    if not day_only:\n",
    "        final.drop(columns=['Cn2_ground','Cn2_150','Cn2_250','Isop','Tau0'],inplace=True)\n",
    "    else:\n",
    "        final.drop(columns=['Cn2_ground','Cn2_150','Cn2_250'],inplace=True)\n",
    "\n",
    "    # Add group index, based on time jumps bigger than 300s (this needs to be in sync with sampling_rate !!)\n",
    "    final['groups'] = (final.index.to_series().diff().dt.seconds > 300).cumsum()\n",
    "\n",
    "    \n",
    "    print('final',final)\n",
    "    \n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b89dcae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gdimm_data                      Seeing  Isop   Tau0\n",
      "Date                                    \n",
      "2018-06-02 02:35:00   0.940  1.47  -1.00\n",
      "2018-06-02 02:40:00   0.780  1.72  -1.00\n",
      "2018-06-03 21:50:00   1.070  1.37   3.48\n",
      "2018-06-03 21:55:00   1.385  1.47   2.70\n",
      "2018-06-03 22:00:00   0.950  1.43   3.31\n",
      "...                     ...   ...    ...\n",
      "2018-06-30 02:20:00   0.575  1.45   4.83\n",
      "2018-06-30 02:25:00   0.480  1.69   5.46\n",
      "2018-06-30 02:30:00   0.450  1.89  30.80\n",
      "2018-06-30 02:35:00   0.490  1.55   6.30\n",
      "2018-06-30 02:40:00   0.495  1.57   7.38\n",
      "\n",
      "[901 rows x 3 columns]\n",
      "pml_data                      Seeing    Cn2_ground       Cn2_150       Cn2_250\n",
      "Date                                                                 \n",
      "2018-06-05 11:30:00  3.3793  2.216900e-14  1.602000e-14  3.025600e-16\n",
      "2018-06-05 11:35:00  2.0115  1.442700e-14  4.339900e-16  1.465600e-15\n",
      "2018-06-05 11:40:00  2.0115  1.442700e-14  4.339900e-16  1.465600e-15\n",
      "2018-06-05 11:45:00  2.0115  1.442700e-14  4.339900e-16  1.465600e-15\n",
      "2018-06-05 11:50:00  2.0115  1.442700e-14  4.339900e-16  1.465600e-15\n",
      "...                     ...           ...           ...           ...\n",
      "2018-06-26 08:50:00  2.5553  1.285800e-14  2.794600e-15  4.207900e-15\n",
      "2018-06-26 08:55:00  2.5553  1.285800e-14  2.794600e-15  4.207900e-15\n",
      "2018-06-26 09:00:00  3.0167  1.558500e-14  5.093600e-15  4.611700e-15\n",
      "2018-06-26 09:05:00  3.0167  1.558500e-14  5.093600e-15  4.611700e-15\n",
      "2018-06-26 09:10:00  1.4642  4.623400e-15  7.853800e-16  6.102200e-17\n",
      "\n",
      "[774 rows x 4 columns]\n",
      "meteo_data                        pressure  Temperature  Humidity  windSpeed     windDir\n",
      "Date                                                                         \n",
      "2018-06-01 00:00:00  878.231931    12.577778        70   3.240154  213.298009\n",
      "2018-06-01 00:05:00  878.326263    12.522222        71   5.664481  225.464661\n",
      "2018-06-01 00:10:00  878.048647    12.577778        71   5.744626  239.311271\n",
      "2018-06-01 00:15:00  878.024267    12.688889        71   5.744626  245.773373\n",
      "2018-06-01 00:20:00  878.189941    12.744444        71   7.066210  251.468612\n",
      "...                         ...          ...       ...        ...         ...\n",
      "2018-06-30 23:35:00  874.182068    19.688889        68   8.313188   12.826832\n",
      "2018-06-30 23:40:00  874.173495    19.577778        70   4.039357   20.178487\n",
      "2018-06-30 23:45:00  874.339189    19.355556        79   6.085680  193.789027\n",
      "2018-06-30 23:50:00  874.265270    19.022222        75   4.273831  215.618481\n",
      "2018-06-30 23:55:00  874.284465    18.911111        77   0.991188  217.419334\n",
      "\n",
      "[7674 rows x 5 columns]\n",
      "to_merge                      Seeing    Cn2_ground       Cn2_150       Cn2_250\n",
      "Date                                                                 \n",
      "2018-06-05 11:30:00  3.3793  2.216900e-14  1.602000e-14  3.025600e-16\n",
      "2018-06-05 11:35:00  2.0115  1.442700e-14  4.339900e-16  1.465600e-15\n",
      "2018-06-05 11:40:00  2.0115  1.442700e-14  4.339900e-16  1.465600e-15\n",
      "2018-06-05 11:45:00  2.0115  1.442700e-14  4.339900e-16  1.465600e-15\n",
      "2018-06-05 11:50:00  2.0115  1.442700e-14  4.339900e-16  1.465600e-15\n",
      "...                     ...           ...           ...           ...\n",
      "2018-06-26 08:50:00  2.5553  1.285800e-14  2.794600e-15  4.207900e-15\n",
      "2018-06-26 08:55:00  2.5553  1.285800e-14  2.794600e-15  4.207900e-15\n",
      "2018-06-26 09:00:00  3.0167  1.558500e-14  5.093600e-15  4.611700e-15\n",
      "2018-06-26 09:05:00  3.0167  1.558500e-14  5.093600e-15  4.611700e-15\n",
      "2018-06-26 09:10:00  1.4642  4.623400e-15  7.853800e-16  6.102200e-17\n",
      "\n",
      "[774 rows x 4 columns]\n",
      "final                        pressure  Temperature  Humidity  windSpeed     windDir  \\\n",
      "Date                                                                            \n",
      "2018-06-05 11:30:00  872.791832    15.911111        89   9.709378  164.650895   \n",
      "2018-06-05 11:35:00  872.821721    15.633333        88  12.928074  160.337436   \n",
      "2018-06-05 11:40:00  872.736816    15.855556        87   8.100030  177.575007   \n",
      "2018-06-05 11:45:00  872.791170    16.077778        88  11.030961  187.431691   \n",
      "2018-06-05 11:50:00  872.779660    15.966667        85  11.414647  173.558383   \n",
      "...                         ...          ...       ...        ...         ...   \n",
      "2018-06-26 08:50:00  878.807820    14.855556        75   3.655671  136.330756   \n",
      "2018-06-26 08:55:00  878.633879    14.911111        76   0.831319  142.782017   \n",
      "2018-06-26 09:00:00  878.645372    15.133333        76   0.010658  143.000000   \n",
      "2018-06-26 09:05:00  878.874178    15.577778        75   1.097767  157.073173   \n",
      "2018-06-26 09:10:00  878.854383    15.966667        74   2.025007  180.189331   \n",
      "\n",
      "                     Seeing    Cn2_ground       Cn2_150       Cn2_250  \n",
      "Date                                                                   \n",
      "2018-06-05 11:30:00  3.3793  2.216900e-14  1.602000e-14  3.025600e-16  \n",
      "2018-06-05 11:35:00  2.0115  1.442700e-14  4.339900e-16  1.465600e-15  \n",
      "2018-06-05 11:40:00  2.0115  1.442700e-14  4.339900e-16  1.465600e-15  \n",
      "2018-06-05 11:45:00  2.0115  1.442700e-14  4.339900e-16  1.465600e-15  \n",
      "2018-06-05 11:50:00  2.0115  1.442700e-14  4.339900e-16  1.465600e-15  \n",
      "...                     ...           ...           ...           ...  \n",
      "2018-06-26 08:50:00  2.5553  1.285800e-14  2.794600e-15  4.207900e-15  \n",
      "2018-06-26 08:55:00  2.5553  1.285800e-14  2.794600e-15  4.207900e-15  \n",
      "2018-06-26 09:00:00  3.0167  1.558500e-14  5.093600e-15  4.611700e-15  \n",
      "2018-06-26 09:05:00  3.0167  1.558500e-14  5.093600e-15  4.611700e-15  \n",
      "2018-06-26 09:10:00  1.4642  4.623400e-15  7.853800e-16  6.102200e-17  \n",
      "\n",
      "[774 rows x 9 columns]\n",
      "final                        pressure  Temperature  Humidity  windSpeed     windDir  \\\n",
      "Date                                                                            \n",
      "2018-06-05 11:30:00  872.791832    15.911111      89.0   9.709378  164.650895   \n",
      "2018-06-05 11:35:00  872.821721    15.633333      88.0  12.928074  160.337436   \n",
      "2018-06-05 11:40:00  872.736816    15.855556      87.0   8.100030  177.575007   \n",
      "2018-06-05 11:45:00  872.791170    16.077778      88.0  11.030961  187.431691   \n",
      "2018-06-05 11:50:00  872.779660    15.966667      85.0  11.414647  173.558383   \n",
      "...                         ...          ...       ...        ...         ...   \n",
      "2018-06-26 08:50:00  878.807820    14.855556      75.0   3.655671  136.330756   \n",
      "2018-06-26 08:55:00  878.633879    14.911111      76.0   0.831319  142.782017   \n",
      "2018-06-26 09:00:00  878.645372    15.133333      76.0   0.010658  143.000000   \n",
      "2018-06-26 09:05:00  878.874178    15.577778      75.0   1.097767  157.073173   \n",
      "2018-06-26 09:10:00  878.854383    15.966667      74.0   2.025007  180.189331   \n",
      "\n",
      "                     Seeing  groups  \n",
      "Date                                 \n",
      "2018-06-05 11:30:00  3.3793       0  \n",
      "2018-06-05 11:35:00  2.0115       0  \n",
      "2018-06-05 11:40:00  2.0115       0  \n",
      "2018-06-05 11:45:00  2.0115       0  \n",
      "2018-06-05 11:50:00  2.0115       0  \n",
      "...                     ...     ...  \n",
      "2018-06-26 08:50:00  2.5553       6  \n",
      "2018-06-26 08:55:00  2.5553       6  \n",
      "2018-06-26 09:00:00  3.0167       6  \n",
      "2018-06-26 09:05:00  3.0167       6  \n",
      "2018-06-26 09:10:00  1.4642       6  \n",
      "\n",
      "[774 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "final = simple_data_preparation(data_dir = r'C:\\Users\\Mary-\\Desktop\\PhD\\First year\\ML LSTM\\forecast-main\\test_data', \n",
    "                     meteo_dir='meteo',meteo_tag='meteo_cats_*.csv',\n",
    "                     gdimm_dir='gdimm',gdimm_tag='new_r0Alt_2*.csv',\n",
    "                     pml_dir='pml',pml_tag='new_Cn2_2*.csv',\n",
    "                     sampling_rate_min=5,interpolate=True,day_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec59952b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_learning_sets(dataframe,input_sequence_length_min=60,\n",
    "                          output_sequence_length_min=30,test_size=0.2,\n",
    "                          sampling_rate_min=5, \n",
    "                          out_column='Temperature',\n",
    "                          return_scaler = True):\n",
    "\n",
    "    '''\n",
    "    This routine first splits the dataframe into training and testing, scales all columns, and finally arrange the\n",
    "    training and testing sets into their final form for training and testing. The final form consists in an array \n",
    "    of time series of input_sequence_length_min minutes and corresponding target time series of \n",
    "    output_sequence_length_min minutes. \n",
    "    '''\n",
    "    n_input_sequence = input_sequence_length_min//sampling_rate_min\n",
    "    n_output_sequence = output_sequence_length_min//sampling_rate_min\n",
    "    n_full_sequence  = n_input_sequence+n_output_sequence\n",
    "    n_features = dataframe.shape[1]\n",
    "    X_train = np.empty((0,n_input_sequence,n_features))\n",
    "    X_test = np.empty((0,n_input_sequence,n_features))\n",
    "    Y_train = np.empty((0,n_output_sequence,1))\n",
    "    Y_test = np.empty((0,n_output_sequence,1))\n",
    "    out_column_index = dataframe.columns.get_loc(out_column)\n",
    "    print('n_full_sequence',n_full_sequence)\n",
    "\n",
    "    for group in np.unique(dataframe['groups']):\n",
    "        current = dataframe[dataframe.groups==group]  #split the groups\n",
    "        \n",
    "\n",
    "        # Split and check that current dataframes have enough samples\n",
    "        train_df, test_df = train_test_split(current,test_size=test_size,shuffle=False)\n",
    "        if (train_df.shape[0] < n_full_sequence or test_df.shape[0] < n_full_sequence):\n",
    "            #print(\"train_df\",train_df.shape[0])\n",
    "            continue\n",
    "            \n",
    "        \n",
    "        \n",
    "        for col in train_df.columns:\n",
    "            scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "            ss = scaler.fit_transform(train_df[col].values.reshape((-1,1)))\n",
    "            \n",
    "            ss = ss.reshape(len(ss)) # Get rid of extra dim\n",
    "            train_df.loc[:,col] = ss\n",
    "            train_df.rename(columns={col:\"scaled_%s\"%col},inplace=True)\n",
    "            if col==out_column:\n",
    "                out_scaler = scaler\n",
    "            # Now process the corresponding column from the test dataframe\n",
    "            ss = scaler.transform(test_df[col].values.reshape((-1,1)))\n",
    "            ss = ss.reshape(len(ss))\n",
    "            test_df.loc[:,col] = ss\n",
    "            test_df.rename(columns={col:\"scaled_%s\"%col},inplace=True)\n",
    "\n",
    "        # scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "        # train_df[train_df.columns] = scaler.fit_transform(train_df)\n",
    "        # test_df[test_df.columns] = scaler.fit_transform(test_df)\n",
    "        # for col in train_df.columns:\n",
    "        #     train_df.rename(columns={col:\"scaled_%s\"%col},inplace=True)\n",
    "        # for col in test_df.columns:\n",
    "        #     test_df.rename(columns={col:\"scaled_%s\"%col},inplace=True)\n",
    "\n",
    "\n",
    "        # Fill missing values\n",
    "        train_df = fill_missing_values(train_df)\n",
    "        test_df  = fill_missing_values(test_df)\n",
    "\n",
    "        # Now chunk the sets\n",
    "        x_train, y_train = split_series(train_df.values,n_input_sequence,n_output_sequence,out_column_index=out_column_index)\n",
    "        x_test,  y_test  = split_series(test_df.values, n_input_sequence,n_output_sequence,out_column_index=out_column_index)\n",
    "\n",
    "        X_train = np.append(X_train,x_train,axis=0)\n",
    "        Y_train = np.append(Y_train,y_train,axis=0)\n",
    "        X_test  = np.append(X_test,x_test,axis=0)\n",
    "        Y_test  = np.append(Y_test,y_test,axis=0)\n",
    "    if (return_scaler):\n",
    "        return(X_train,Y_train,X_test,Y_test,out_scaler)\n",
    "    else:\n",
    "        return (X_train,Y_train,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7170144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_full_sequence 18\n",
      "train_df                        pressure  Temperature  Humidity  windSpeed     windDir  \\\n",
      "Date                                                                            \n",
      "2018-06-18 05:55:00  876.340446    15.911111      83.0   8.878059  107.580517   \n",
      "2018-06-18 06:00:00  876.361866    15.966667      82.0   7.886871  105.868135   \n",
      "2018-06-18 06:05:00  876.334354    16.188889      81.0   9.410956  111.989589   \n",
      "2018-06-18 06:10:00  876.426859    16.466667      80.0  10.892408  110.356229   \n",
      "2018-06-18 06:15:00  876.386192    16.466667      79.0   9.741351  110.317941   \n",
      "...                         ...          ...       ...        ...         ...   \n",
      "2018-06-18 17:50:00  878.915252    19.855556      70.0  13.567550  196.457311   \n",
      "2018-06-18 17:55:00  878.882615    19.800000      70.0  13.876630  199.159137   \n",
      "2018-06-18 18:00:00  878.934396    19.688889      70.0  14.644001  199.055965   \n",
      "2018-06-18 18:05:00  878.977564    19.688889      71.0  11.478595  207.785046   \n",
      "2018-06-18 18:10:00  878.951911    19.522222      72.0   9.805299  231.554083   \n",
      "\n",
      "                     Seeing  groups  \n",
      "Date                                 \n",
      "2018-06-18 05:55:00  0.7644       1  \n",
      "2018-06-18 06:00:00     NaN       1  \n",
      "2018-06-18 06:05:00  0.8528       1  \n",
      "2018-06-18 06:10:00  0.8528       1  \n",
      "2018-06-18 06:15:00  1.2559       1  \n",
      "...                     ...     ...  \n",
      "2018-06-18 17:50:00  1.6790       1  \n",
      "2018-06-18 17:55:00  1.6790       1  \n",
      "2018-06-18 18:00:00  1.6790       1  \n",
      "2018-06-18 18:05:00  1.6790       1  \n",
      "2018-06-18 18:10:00  1.6790       1  \n",
      "\n",
      "[148 rows x 7 columns]\n",
      "train_df                        pressure  Temperature  Humidity  windSpeed     windDir  \\\n",
      "Date                                                                            \n",
      "2018-06-19 06:00:00  880.678192    16.855556      77.0   3.453171  102.306920   \n",
      "2018-06-19 06:05:00  880.495565    16.855556      77.0   6.362786  105.882333   \n",
      "2018-06-19 06:10:00  880.498737    16.911111      77.0   6.789104  112.529240   \n",
      "2018-06-19 06:15:00  880.763724    17.022222      76.0   8.931349  108.050001   \n",
      "2018-06-19 06:20:00  880.543121    17.077778      75.0   8.355820  106.896083   \n",
      "...                         ...          ...       ...        ...         ...   \n",
      "2018-06-19 18:35:00  880.999161    21.911111      61.0   9.826615  206.771812   \n",
      "2018-06-19 18:40:00  880.989402    21.744444      61.0   8.419768  222.804391   \n",
      "2018-06-19 18:45:00  880.998489    21.633333      62.0   6.234891  229.351416   \n",
      "2018-06-19 18:50:00  880.920508    21.800000      62.0   8.270557  199.984331   \n",
      "2018-06-19 18:55:00  880.846248    21.800000      61.0   5.680679  201.450615   \n",
      "\n",
      "                     Seeing  groups  \n",
      "Date                                 \n",
      "2018-06-19 06:00:00  1.1020       2  \n",
      "2018-06-19 06:05:00  1.6462       2  \n",
      "2018-06-19 06:10:00  1.6462       2  \n",
      "2018-06-19 06:15:00  1.6462       2  \n",
      "2018-06-19 06:20:00  1.4357       2  \n",
      "...                     ...     ...  \n",
      "2018-06-19 18:35:00  1.3204       2  \n",
      "2018-06-19 18:40:00  1.3204       2  \n",
      "2018-06-19 18:45:00  1.3204       2  \n",
      "2018-06-19 18:50:00  1.3204       2  \n",
      "2018-06-19 18:55:00  1.3204       2  \n",
      "\n",
      "[156 rows x 7 columns]\n",
      "train_df                        pressure  Temperature  Humidity  windSpeed     windDir  \\\n",
      "Date                                                                            \n",
      "2018-06-20 13:05:00  882.000372    20.300000      62.0   7.609765  145.482971   \n",
      "2018-06-20 13:10:00  882.095725    20.188889      65.0   8.643584  146.521073   \n",
      "2018-06-20 13:15:00  882.014780    20.300000      63.0   6.735814  159.509420   \n",
      "2018-06-20 13:20:00  882.085774    20.522222      65.0   4.103305  154.118076   \n",
      "2018-06-20 13:25:00  882.030459    20.577778      63.0   8.132003  156.935386   \n",
      "...                         ...          ...       ...        ...         ...   \n",
      "2018-06-20 20:10:00  880.543058    18.688889      70.0   4.646859  285.027501   \n",
      "2018-06-20 20:15:00  880.539877    18.633333      70.0   4.902650  285.000000   \n",
      "2018-06-20 20:20:00  880.481370    18.633333      70.0   3.762251  275.338491   \n",
      "2018-06-20 20:25:00  880.572312    18.688889      70.0   6.554629  275.064961   \n",
      "2018-06-20 20:30:00  880.569131    18.633333      70.0   6.458708  275.000000   \n",
      "\n",
      "                     Seeing  groups  \n",
      "Date                                 \n",
      "2018-06-20 13:05:00  3.4424       3  \n",
      "2018-06-20 13:10:00  2.3459       3  \n",
      "2018-06-20 13:15:00  2.2270       3  \n",
      "2018-06-20 13:20:00  2.8964       3  \n",
      "2018-06-20 13:25:00  3.0585       3  \n",
      "...                     ...     ...  \n",
      "2018-06-20 20:10:00  0.9783       3  \n",
      "2018-06-20 20:15:00  0.6241       3  \n",
      "2018-06-20 20:20:00  0.6975       3  \n",
      "2018-06-20 20:25:00  0.8213       3  \n",
      "2018-06-20 20:30:00  0.6813       3  \n",
      "\n",
      "[90 rows x 7 columns]\n",
      "train_df                        pressure  Temperature  Humidity  windSpeed     windDir  \\\n",
      "Date                                                                            \n",
      "2018-06-21 05:40:00  879.505232    17.022222      71.0   9.720036  327.995576   \n",
      "2018-06-21 05:45:00  879.508173    17.077778      71.0   8.632926  321.961526   \n",
      "2018-06-21 05:50:00  879.511123    17.133333      71.0   7.865555  316.669580   \n",
      "2018-06-21 05:55:00  879.543342    17.188889      71.0   7.172789  314.546807   \n",
      "2018-06-21 06:00:00  879.540263    17.355556      70.0   6.352129  315.000000   \n",
      "...                         ...          ...       ...        ...         ...   \n",
      "2018-06-21 19:00:00  876.863461    17.688889      87.0   6.810420  354.356925   \n",
      "2018-06-21 19:05:00  876.934388    17.355556      85.0  17.095326  346.546431   \n",
      "2018-06-21 19:10:00  876.571899    16.911111      87.0  19.237570  326.626028   \n",
      "2018-06-21 19:15:00  876.687277    16.966667      86.0  16.061506  299.305265   \n",
      "2018-06-21 19:20:00  876.590027    17.188889      84.0  11.393331  264.914938   \n",
      "\n",
      "                     Seeing  groups  \n",
      "Date                                 \n",
      "2018-06-21 05:40:00  0.4399       4  \n",
      "2018-06-21 05:45:00  0.5376       4  \n",
      "2018-06-21 05:50:00  0.6355       4  \n",
      "2018-06-21 05:55:00  0.8797       4  \n",
      "2018-06-21 06:00:00  0.8346       4  \n",
      "...                     ...     ...  \n",
      "2018-06-21 19:00:00  1.7243       4  \n",
      "2018-06-21 19:05:00  1.7243       4  \n",
      "2018-06-21 19:10:00  1.7243       4  \n",
      "2018-06-21 19:15:00  1.7243       4  \n",
      "2018-06-21 19:20:00  1.7243       4  \n",
      "\n",
      "[165 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "Xtrain,Ytrain,Xtest,Ytest,out_scaler =  prepare_learning_sets(final,input_sequence_length_min=60,\n",
    "                          output_sequence_length_min=30,test_size=0.2,\n",
    "                          sampling_rate_min=5, \n",
    "                          out_column='Temperature',\n",
    "                          return_scaler = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc58bc26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
